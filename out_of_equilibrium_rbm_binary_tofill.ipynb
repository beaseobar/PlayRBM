{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4VyZvDknS-1K",
    "outputId": "b378b8be-e3cb-42bc-92da-35954526eb26"
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio numpy matplotlib h5py pandas scikit-learn scipy tqdm\n",
    "!pip install git+https://github.com/AurelienDecelle/TorchRBM.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yvd13wcWbuFg"
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from rbm.binary.functions import init_chains\n",
    "from rbm.binary.sampling import sample_state,sample_hiddens\n",
    "from rbm.binary.train import train\n",
    "from rbm.custom_fn import compute_U\n",
    "from rbm.dataset import DatasetRBM\n",
    "from rbm.io import load_params\n",
    "from rbm.plot import plot_PCA\n",
    "from rbm.utils import get_eigenvalues_hystory\n",
    "from rbm.utils import get_checkpoints as get_checkpoints_trained\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Found device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-gYZuU7UwNM"
   },
   "outputs": [],
   "source": [
    "# Some utility functions\n",
    "def ImConcat(X,ncol=10,nrow=5,sx=28,sy=28):\n",
    "        tile_X = []\n",
    "        for c in range(nrow):\n",
    "            L = torch.cat((tuple(X[i,:].reshape(sx,sy) for i in np.arange(c*ncol,(c+1)*ncol))))\n",
    "            tile_X.append(L)\n",
    "        return torch.cat(tile_X,1)\n",
    "def plot_image(sample, shape=(28, 28), grid_size=(10, 10), show_grid=False):\n",
    "    num_samples = grid_size[0] * grid_size[1]\n",
    "    id_sample = np.random.randint(0, sample.shape[0], num_samples)\n",
    "    display = np.zeros((shape[0] * grid_size[0], shape[1] * grid_size[1]))\n",
    "    for i, id_s in enumerate(id_sample):\n",
    "        idx, idy = i % grid_size[0], i // grid_size[1]\n",
    "        display[\n",
    "            (idx * shape[0]) : ((idx + 1) * shape[0]),\n",
    "            (idy * shape[1]) : (idy + 1) * shape[1],\n",
    "        ] = sample[id_s].reshape(shape[0], shape[1])\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.imshow(display, cmap=\"gray\")\n",
    "    if show_grid:\n",
    "        # Minor ticks\n",
    "        ax.set_xticks(np.arange(-0.5, grid_size[0] * shape[0], shape[0]), minor=True)\n",
    "        ax.set_yticks(np.arange(-0.5, grid_size[1] * shape[1], shape[1]), minor=True)\n",
    "\n",
    "        # Gridlines based on minor ticks\n",
    "        ax.grid(which=\"minor\", color=\"gray\", linestyle=\"-\", linewidth=2)\n",
    "        ax.imshow(display, cmap=\"gray\")\n",
    "    else:\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "def get_checkpoints(n_save: int, num_updates: int, spacing: str = \"exp\"):\n",
    "    if spacing == 'exp':\n",
    "        checkpoints = []\n",
    "        xi = num_updates\n",
    "        for _ in range(n_save):\n",
    "            checkpoints.append(xi)\n",
    "            xi = xi / num_updates**(1 / n_save)\n",
    "        checkpoints = np.unique(np.array(checkpoints, dtype=np.int32))\n",
    "    elif spacing == 'linear':\n",
    "        checkpoints = np.linspace(1, num_updates, n_save).astype(np.int32)\n",
    "    checkpoints = np.unique(np.append(checkpoints, num_updates))\n",
    "    return checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJG8HT2LU_1_"
   },
   "source": [
    "\n",
    "# Create the dataset\n",
    "\n",
    "Colab provides us with several datasets, among which we can start with [MNIST](http://yann.lecun.com/exdb/mnist/) which contains 28$\\times$28 pixel images of handwritten digits in white and black using variables that range from 0 to 255. Original data is in grey scale, but we will be working with binary black/white (or 0, 1 for us) variables. For this reason, we rewrite the dataset so that all pixels with $I/255>0.3$ is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9QQjE3Z4Vp-E",
    "outputId": "f3678f89-0736-42c0-c6b7-1cc276bceaf7"
   },
   "outputs": [],
   "source": [
    "my_data = np.genfromtxt('sample_data/mnist_train_small.csv', delimiter=',')\n",
    "labels, dataset = my_data[:,0], my_data[:,1:]\n",
    "print(labels)\n",
    "# Convert to binary dataset\n",
    "dataset /= 255.\n",
    "data = np.array(dataset > 0.3, dtype=float)\n",
    "# write to .dat\n",
    "np.savetxt(\"MNIST.dat\", data)\n",
    "data=torch.tensor(data,device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1iHrVXiGjtiJ"
   },
   "source": [
    "We show a subsample of all the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "kvPBUjBiZje0",
    "outputId": "0d2f1f0a-6fc7-4850-b1cc-c5e0cc775d1f"
   },
   "outputs": [],
   "source": [
    "plot_image(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RbCgq7_Ij-tZ"
   },
   "source": [
    "<font color='red'>\n",
    "\n",
    "This is a standard data set for classification applications. For this reason, we also know the digit represented in each image, even if we will not use it for our training, as we will be working in a completely unsupervised setup.\n",
    "1. Visualize the first entry of our thresholded dataset with `plt.imshow()`. Our data are vectors with 784 entries. In order to display them as an image, we need to transform them into a $28\\times 28$ tensor. You can do this with `.reshape(28,28)`. You may need to transform the data to `.cpu()` before plotting it.\n",
    "2. `print` the corresponding label\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "pBYVNwKukYQ-",
    "outputId": "8aee3524-29d1-494b-be22-753a13d73f85"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dimensional reduction PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reduce the dimension of the dataset (784) to visualize it in lower dimensions. For this goal, we need to obtain the principal directions of the dataset which are nothing but the eigenvectors of the covariance matrix of the data. \n",
    "\n",
    "<font color='red'>\n",
    "\n",
    "1. Our dataset $X$ is a $M\\times d$ matrix, where $M$ is the number of samples and $d$ the dimension of our data. In this way, the entry $x_{mi}$ contains the $i$th pixel in the $m$-th example. Which are our $M$ and $d$? You can check the dimension of a tensor `X` using `X.shape`.\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "3. Compute the empirical covariance matrix of the data\n",
    "$$\\boldsymbol Q=\\frac{1}{M-1} (\\boldsymbol X-\\overline{\\boldsymbol X})^\\top (\\boldsymbol X-\\overline{\\boldsymbol X})\\quad \\text{or}\\quad Q_{ij}=\\frac{1}{M-1} \\sum_{m=1}^M (x_{mi}-\\overline{x_i})(x_{mj}-\\overline{x_j})$$\n",
    "You can use \n",
    "\n",
    "`torch.cov(data.T)`\n",
    "\n",
    "or do it yourself using matrix multiplications. Which should be its dimension?\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "3. Diagonalize the Q matrix with \n",
    "\n",
    "\n",
    "`Σ,U= torch.linalg.eig(Q)`\n",
    "\n",
    "    \n",
    "where `Σ` is a vector containing all the eigenvalues, and `U` the matrix that contains the corresponding eigenvectors in its columns, and\n",
    "$Q=U^{-1} \\Sigma U$. Transform `U=U.double()` to avoid dealing with complex variables\n",
    "\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "    \n",
    "4. Visualize the first 5 principal directions (the eigenvectors with the 5 largest eigenvalues) as images using `plt.imshow()`. The `i`-th column of a bidimensional tensor is extracted as `U[:,i]`\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,5)\n",
    "for i in range(5):\n",
    "    ax[i].imshow(#####.reshape(28,28).cpu(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "    \n",
    "5. Project each entry of the dataset along the first two principal components and show them in a scatter plot using the code below. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj=(data@U).cpu()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "scatter=plt.scatter(###,marker='.',c=labels,cmap='Spectral')\n",
    "legend1 = ax.legend(*scatter.legend_elements(),loc=\"lower right\", title=\"labels\",ncols=2)\n",
    "ax.add_artist(legend1)\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "noGxGgy_hvPQ"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform a very short training process. First, we need to set the hyperparameters. We will take them into account:\n",
    "- $N_\\mathrm{h}=100$ hidden nodes\n",
    "- $10^4$ parameter updates\n",
    "- Use 2000 parallel chains to estimate the MCMC averages. Each time we change the parameters, we will perform $k=10$ steps.\n",
    "- At the moment we use the persistent contrastive divergence (PCD) recipe. This means that every time we change the parameters, we restart the Markov chains at the last configurations reached in the previous update. We will try other schemes later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f_E8utGiWMZX"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "num_hiddens = 100 # no. of hidden nodes\n",
    "\n",
    "num_updates = 10_000 # no. of parameter updates\n",
    "\n",
    "learning_rate = 0.05    # lr \n",
    "batch_size = 2000       # minibatch for the stochastic gradient descent \n",
    "num_chains = batch_size # no. of chains for the MCMC \n",
    "gibbs_steps = 10        # no. of Gibbs updates \n",
    "\n",
    "training_scheme=\"PCD\" # we can choose among \"PCD\", \"Rdm\", \"CD\" \n",
    "\n",
    "checkpoints = get_checkpoints(n_save=100, num_updates=num_updates) # we want to save several machines (100) along the training trajectory\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "dataset = DatasetRBM(\"MNIST.dat\", device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "mI2OkZGvZg67",
    "outputId": "416f2984-4d32-4e8a-8f91-56c59871ea80"
   },
   "source": [
    "We run the training process and save the evolution of the parameters in the file `RBMPCD.h5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2-zdbOE8WStE"
   },
   "outputs": [],
   "source": [
    "train(\n",
    "    filename=\"RBM\"+training_scheme+\".h5\",\n",
    "    dataset=dataset,\n",
    "    num_updates=num_updates,\n",
    "    num_hiddens=num_hiddens,\n",
    "    training_mode=training_scheme,\n",
    "    lr=learning_rate,\n",
    "    batch_size=batch_size,\n",
    "    num_chains=num_chains,\n",
    "    gibbs_steps=gibbs_steps,\n",
    "    checkpoints=checkpoints,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File `RBM.h5` contains all the information about the training process. We can extract the samples in the permanent chain from `f[\"parallel_chains\"][()]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BBAshBOObATQ",
    "outputId": "22cb17c7-8cf5-4d96-b25a-a11dc8b3897f"
   },
   "outputs": [],
   "source": [
    "fname_data = \"MNIST.dat\"\n",
    "fname_model = \"RBMPCD.h5\"\n",
    "with h5py.File(fname_model, \"r\") as f:\n",
    "    for key in f[\"hyperparameters\"].keys():\n",
    "        print(key, f[\"hyperparameters\"][key][()])\n",
    "        \n",
    "    num_hiddens = f[\"hyperparameters\"][\"num_hiddens\"][()]\n",
    "    chains = torch.tensor(f[\"parallel_chains\"][()], device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font color='red'> \n",
    "    \n",
    "Let's give a look to the permanent chain. \n",
    "     \n",
    "2. Which is the dimension of the permanent chain `chains`?\n",
    "3. Visualize the different parallel chains as images using the function `plot_image` used above for the dataset.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> \n",
    "\n",
    "As discussed in the class, we can use different recipes to initialize the MCMC simulations we use to compute the gradient. In particular, we are going to compare the performance for:\n",
    "- (PCD) Persistent Contrastive Divergence. We maintain a \"permanent chain\", i.e., we always iterate on the same chain, or in other words, we initialize the Markov chain process at each update on the last configurations reached at the previous update.\n",
    "- (Rdm): We always initialize the chains with random conditions.\n",
    "- (CD): We always initialize the chains with the samples in the minibatch\n",
    "\n",
    "1. We had already run a short training using PCD. Rerun the training process using the Rdm and CD recipes. The different models will be stored in different files `RBMPCD.h5`, `RBMPCD.h5`, `RBMCD.h5`.\n",
    "2. Compare the images of the file chain obtained with each method, which corresponds to the last configurations generated in the last training update. \n",
    "3. Project the chain on the first two principal directions of the dataset\n",
    "\n",
    "`data_proj = data @ U`\n",
    "\n",
    "`chains_proj = chains @ U`\n",
    "\n",
    "`plot_PCA(data_proj.cpu().numpy(), chains_proj.cpu().numpy(), labels=[\"dataset\", f\"Last chains\"])`\n",
    "\n",
    "4. Do you see any particular difference?\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rec in ['PCD','Rdm','CD']:\n",
    "    \n",
    "    fname_model = \"RBM\"+rec+\".h5\"\n",
    "    with h5py.File(fname_model, \"r\") as f:\n",
    "        chains = torch.tensor(f[\"parallel_chains\"][()], device=device)\n",
    "        \n",
    "        chains_proj = ###\n",
    "\n",
    "        ######\n",
    "\n",
    "        plot_PCA(data_proj.cpu().numpy(), chains_proj.cpu().numpy(), labels=[\"dataset\", f\"Last chains\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4AwSfV8uqpIs"
   },
   "source": [
    "## Generating Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have trained the models, we can generate new samples through a MCMC process.  We select the parameters of the most trained model, initialize a set of `n_gen` parallel samples, and run a sampling process of `mcmc_steps`. \n",
    "\n",
    "<font color='red'> \n",
    "\n",
    "1. Using the PCD training, try to check how much time you need to thermalize the chains and start to generate samples with the code below. We can visualize the samples both by looking at the images, or by looking at their PCA.\n",
    "\n",
    "2. We can either visualize the visible units by selecting the key `v` or the magnetizations `mv`. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 854
    },
    "id": "eeMdOBL6cf-D",
    "outputId": "c8c30b93-5ac8-4741-edab-8788bd1aca22"
   },
   "outputs": [],
   "source": [
    "rec='CD'\n",
    "fname_model = \"RBM\"+rec+\".h5\"\n",
    "\n",
    "n_gen = 5000\n",
    "mcmc_steps = 10\n",
    "checkpoint = get_checkpoints_trained(fname_model)[-1] # we select the last update saved in the folder\n",
    "params = load_params(fname=fname_model, device=device, checkpoint=checkpoint) # extract the parameters of the model\n",
    "\n",
    "chains_init = init_chains(num_chains=n_gen, num_visibles=num_visibles, num_hiddens=num_hiddens, device=device) # initialize ramdomly the chains\n",
    "\n",
    "\n",
    "gen = sample_state(chains=chains_init, params=params, gibbs_steps=mcmc_steps)[\"mv\"] # sample the model for mcmc_steps and extract the configurations\n",
    "\n",
    "gen_proj = gen @ U.float() \n",
    "\n",
    "plot_image(gen.cpu().numpy())\n",
    "plot_PCA(data_proj.cpu().numpy(), gen_proj.cpu().numpy(), labels=[\"dataset\", f\"{mcmc_steps} generation steps\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to visualize the evolution of 15 parallel independent chains during the sampling process using the code below in which we show the images we generate as a function of time for times that grow exponentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UEHjpYG4q3Dd",
    "outputId": "2269cb02-d8ef-4091-d274-e02e850e21d0"
   },
   "outputs": [],
   "source": [
    "n_gen=num_chains\n",
    "checkpoint = get_checkpoints_trained(fname_model)[-1]\n",
    "params = load_params(fname=fname_model, device=device, checkpoint=checkpoint)\n",
    "chains_init = init_chains(num_chains=n_gen, num_visibles=num_visibles, num_hiddens=num_hiddens, device=device)\n",
    "\n",
    "\n",
    "all_vis_datatest=[]\n",
    "vis =chains_init\n",
    "all_vis_datatest.append(vis[\"v\"])\n",
    "\n",
    "\n",
    "x3=np.unique(np.logspace(0,5,base=10,num=16,dtype=int))\n",
    "\n",
    "t_tot=0\n",
    "\n",
    "for t in x3:\n",
    "    #print(t)\n",
    "    Δt = t-t_tot\n",
    "    state=sample_state(chains=vis, params=params, gibbs_steps=int(Δt))\n",
    "    vis=state\n",
    "    C_gen=torch.cov(state[\"v\"].T)\n",
    "    \n",
    "    m_vis=state[\"mv\"]\n",
    "    t_tot += Δt\n",
    "    all_vis_datatest.append(m_vis)\n",
    "    \n",
    "\n",
    "\n",
    "times=[0]\n",
    "times.extend(x3)\n",
    "\n",
    "all_vis_1=all_vis_datatest\n",
    "f,ax = plt.subplots(len(all_vis_1),dpi=100)\n",
    "for i in range(len(all_vis_1)):\n",
    "    Im = ImConcat(all_vis_1[i].cpu(),ncol=1,nrow=15)\n",
    "    ax[i].imshow(Im,cmap='gray')\n",
    "    ax[i].set_xticks([], [])\n",
    "    ax[i].set_yticks([], [])\n",
    "    ax[i].text(5, 5, str(int(times[i])), bbox={'facecolor': 'white', 'pad':1},fontsize=5) #: 5,fontsize : 5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "3. Repeat the same process using the other two training recipes. What difference do you observe? How much time do you need to generate numbers with each recipe?\n",
    "\n",
    "4. What happens now if you change the initialization of the chains. For instance, we can initialize the Markov chains on samples of the dataset using\n",
    "   `chains_init = {\"v\" : dataset.data[:n_gen]}`\n",
    "   \n",
    "   `chains_init = sample_hiddens(chains_init, params)`\n",
    "\n",
    "5. Let us try to quantify the quality of the samples in sampling time. For that, we can compute the Pearson correlation between the dataset and the generated set covariance matrix. You can compute it for each time using\n",
    "\n",
    "   `torch.corrcoef(torch.vstack([C_data.reshape(-1), C_gen.reshape(-1)]))[0, 1].cpu()`\n",
    "\n",
    "    Plot the evolution of the Pearson in time for the three training processes.\n",
    "\n",
    "6. For the `Rdm` recipe prove a change the number of Gibbs steps used to train the machine. Where does the best quality is generated?\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rec in ['PCD','CD','Rdm']:\n",
    "    \n",
    "    fname_model = \"RBM\"+rec+\".h5\"\n",
    "    n_gen=num_chains\n",
    "    checkpoint = get_checkpoints_trained(fname_model)[-1]\n",
    "    params = load_params(fname=fname_model, device=device, checkpoint=checkpoint)\n",
    "    chains_init = init_chains(num_chains=n_gen, num_visibles=num_visibles, num_hiddens=num_hiddens, device=device)\n",
    "    \n",
    "    \n",
    "    all_vis_datatest=[]\n",
    "    vis =chains_init\n",
    "    all_vis_datatest.append(vis[\"v\"])\n",
    "    \n",
    "    \n",
    "    x3=np.unique(np.logspace(0,5,base=10,num=14,dtype=int))\n",
    "    \n",
    "    t_tot=0\n",
    "    ##\n",
    "    for t in x3:\n",
    "        #print(t)\n",
    "        Δt = t-t_tot\n",
    "        state=sample_state(chains=vis, params=params, gibbs_steps=int(Δt))\n",
    "        vis=state\n",
    "        C_gen=torch.cov(state[\"v\"].T)\n",
    "        \n",
    "        \n",
    "        #####\n",
    "        \n",
    "        m_vis=state[\"mv\"]\n",
    "        t_tot += Δt\n",
    "        all_vis_datatest.append(m_vis)\n",
    "        \n",
    "    pearson_coef=np.array(pearson_coef)\n",
    "    plt.plot(x3,pearson_coef,label=rec)\n",
    "\n",
    "plt.ahline(y=10,label=r'$k=10$ training')\n",
    "plt.xscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training dynamics and phase transitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training of the RBMs can be very well tracked using the singular value decomposition of the model weight matrix. We show below the evolution of the singular values (the eigenvalues for a rectangular matrix) in training time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec=\"PCD\"\n",
    "fname_model = \"RBM\"+rec+\".h5\"\n",
    "\n",
    "updates, eigenvalues = get_eigenvalues_hystory(fname_model)\n",
    "\n",
    "fig, ax = plt.subplots(dpi=100, nrows=1, ncols=1, figsize=(6, 3))\n",
    "ax.set_title('weight matrix eigenvalues', size=15)\n",
    "ax.set_xlabel('gradient updates')\n",
    "ax.set_ylabel(r'$w_\\alpha$')\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.grid(alpha=0.5, ls='dashed')\n",
    "ax.plot(updates, eigenvalues);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will see that at the first stages of the training, the singular vectors of the W matrix align with the principal components of the dataset. \n",
    "\n",
    "<font color='red'> \n",
    "\n",
    "1. Show the first 5 principal components of the dataset as done above and compare them with the first 5 singular vectors of W at t=99. What happens at later times?\n",
    "\n",
    "</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(fname_model, 'r')\n",
    "it=99\n",
    "key='update_'+str(it)\n",
    "weight_matrix = torch.tensor(f[key][\"weight_matrix\"][()],device=device)\n",
    "\n",
    "UU,w,VV=torch.svd(weight_matrix)\n",
    "\n",
    "fig, ax = plt.subplots(1,5)\n",
    "fig.suptitle('PCA components',y=.7)\n",
    "for i in range(5):\n",
    "    ax[i].imshow(###.cpu().reshape(28,28), cmap=\"gray\")\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1,5)\n",
    "fig.suptitle('singular vectors',y=.7)\n",
    "for i in range(5):\n",
    "    \n",
    "    ax[i].imshow(###.cpu().reshape(28,28), cmap=\"gray\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We will see in class that the training process can be seen as a sequence of phase transitions. For this reason, for different number of training updates, we will compute the susceptibility associated to the magnetization of the data projected on the first 5 singular vectors of W ($\\boldsymbol{u}_\\alpha$ with $\\alpha=1,\\ldots,5$) as\n",
    "   $$\\chi_\\alpha(t)=N \\left(\\overline{m_\\alpha^2}-\\overline{m}^2\\right)$$\n",
    "with\n",
    "$$m_\\alpha= \\frac{1}{\\sqrt{N}}\\sum_i u_{i}^\\alpha v_i$$\n",
    "and where the averages are computed using the parallel chains.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mcmc_steps=100\n",
    "n_gen = 5000\n",
    "\n",
    "chains_init = init_chains(num_chains=n_gen, num_visibles=num_visibles, num_hiddens=num_hiddens, device=device)\n",
    "chains=chains_init\n",
    "\n",
    "pearson_coef=[]\n",
    "proj=[]\n",
    "eigenvalues=[]\n",
    "for it in updates:\n",
    "    \n",
    "    params = load_params(fname=fname_model, device=device, checkpoint=it)\n",
    "    weight_matrix=params[\"weight_matrix\"]\n",
    "    UU,w,VV=torch.svd(weight_matrix)\n",
    "    eigenvalues.append(np.array(w.cpu()))\n",
    "    \n",
    "    chains = sample_state(chains=chains, params=params, gibbs_steps=mcmc_steps)\n",
    "    \n",
    "    m=chains[\"v\"]@UU.float()/np.sqrt(num_visibles)\n",
    "    \n",
    "    chi=torch.mean((m-m.mean(0))**2,0)\n",
    "    proj.append(np.array(chi.cpu())*num_visibles)\n",
    "\n",
    "fig,ax=plt.subplots(2,1,sharex=True)\n",
    "eigenvalues=np.array(eigenvalues)\n",
    "ax[0].plot(updates,eigenvalues[:,:5])\n",
    "ax[0].set_xlabel('updates')\n",
    "ax[0].set_ylabel(r'$w_\\alpha$')\n",
    "proj=np.array(proj)\n",
    "\n",
    "ax[1].plot(updates,proj[:,:5])\n",
    "plt.legend()\n",
    "plt.xscale('log')\n",
    "ax[1].set_xlabel('updates')\n",
    "ax[1].set_ylabel(r'$\\chi_\\alpha$')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> \n",
    "\n",
    "2. Plot the susceptibility along each mode against the singular value along that mode.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
